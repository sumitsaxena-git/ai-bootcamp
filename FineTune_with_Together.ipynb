{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1283cf2e89a74f9e986ec867d3b70fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cec98fed4f24d72a46da22bd64a3397",
              "IPY_MODEL_2b579f8ed21049dbb566c66da349456e",
              "IPY_MODEL_aad85dfe33ee48ad8dffe702d99f165f"
            ],
            "layout": "IPY_MODEL_1fb0d7f29405491296f2ce8503ff16e1"
          }
        },
        "4cec98fed4f24d72a46da22bd64a3397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de49ba4f1183410fa42bedb8b4334ef0",
            "placeholder": "​",
            "style": "IPY_MODEL_5d5c3eb1d8594dfe885406404294e11c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2b579f8ed21049dbb566c66da349456e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a53c3494eeda46439c693f02a1d4bbc9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28e9f18994144ca8a5e924b88f564ca0",
            "value": 2
          }
        },
        "aad85dfe33ee48ad8dffe702d99f165f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d23901785d8149878af815d56585bc79",
            "placeholder": "​",
            "style": "IPY_MODEL_0ad3a3ae24544bb9adcbc272f8e071e3",
            "value": " 2/2 [00:24&lt;00:00, 10.57s/it]"
          }
        },
        "1fb0d7f29405491296f2ce8503ff16e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de49ba4f1183410fa42bedb8b4334ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d5c3eb1d8594dfe885406404294e11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a53c3494eeda46439c693f02a1d4bbc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28e9f18994144ca8a5e924b88f564ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d23901785d8149878af815d56585bc79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad3a3ae24544bb9adcbc272f8e071e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53101483739f487bb495d85e69753467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecefaf97315d49ddb2c4c10e25ef009c",
              "IPY_MODEL_98aa77db4be343b98c226164158b4f99",
              "IPY_MODEL_fb8f1cabc6614cae97041576f6058ceb"
            ],
            "layout": "IPY_MODEL_723d702b8dd24bc4ae561565c16fe3d2"
          }
        },
        "ecefaf97315d49ddb2c4c10e25ef009c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6babd38e9204d2d88a34a8ad593b6a3",
            "placeholder": "​",
            "style": "IPY_MODEL_0d958d07676b46edac59aebea0d3480a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "98aa77db4be343b98c226164158b4f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ef3453c23c44c3688609863eb5541a3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b87fc7f13f114334ae98ee786a7c342d",
            "value": 2
          }
        },
        "fb8f1cabc6614cae97041576f6058ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec0cfc8f9257408aa0317596f08b968b",
            "placeholder": "​",
            "style": "IPY_MODEL_74564ed0749749e9ab083601c2d5d7db",
            "value": " 2/2 [00:31&lt;00:00, 13.39s/it]"
          }
        },
        "723d702b8dd24bc4ae561565c16fe3d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6babd38e9204d2d88a34a8ad593b6a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d958d07676b46edac59aebea0d3480a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ef3453c23c44c3688609863eb5541a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b87fc7f13f114334ae98ee786a7c342d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec0cfc8f9257408aa0317596f08b968b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74564ed0749749e9ab083601c2d5d7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumitsaxena-git/ai-bootcamp/blob/main/FineTune_with_Together.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modern AI Pro: Finetuning with Together AI\n",
        "The goal of this session is to finetune a 3B parameter model with a very small dataset. We will show what the pre-trained model does (checked from Together Playground) -- produce a lot of innacurate results. The fine-tuned model fixes those issues.\n",
        "\n",
        "Exercise 1: Finetune RedPajama 3B Chat model with a small anti-hallucination dataset. It gives some results that are accurate, but doesn't do too much due to its small size.\n",
        "\n",
        "Exercise 2: Finetune the same model with a slightly bigger dataset on Indian law. This is from real world and thus had to be cleaned up and organized better. And we will see how we can achieve significantly good outcome.\n",
        "\n",
        "You will need an API key for this and each exercse would cost about $5 in credits (as of Feb 2024).\n"
      ],
      "metadata": {
        "id": "0dQ9a26abYN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The legal dataset we used for finetuning is [here](https://drive.google.com/file/d/1PpbMh96Cg_G0qKEAprD42wV29LuPoxYi/view?usp=sharing)."
      ],
      "metadata": {
        "id": "2dml31Vt5rCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fun fact: Our open source model `Red Pajama` is named after a children's book, which is reference to Llama :)\n",
        "https://m.media-amazon.com/images/I/A1OQ1R+4npL._AC_UF1000,1000_QL80_.jpg"
      ],
      "metadata": {
        "id": "1sM_zPz7f5wF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpj0T4KmAnMz",
        "outputId": "f5e78ea9-813e-4d96-9830-8e33a0b1bccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q together\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import together\n",
        "from google.colab import userdata\n",
        "\n",
        "together.api_key = userdata.get('TOGETHER_API_KEY')"
      ],
      "metadata": {
        "id": "kkjE4jx9EsS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We will download a very small dataset in jsonl format\n",
        "From this [paper](https://arxiv.org/abs/2303.08896)"
      ],
      "metadata": {
        "id": "sJU1-bXNb7ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://huggingface.co/datasets/clam004/antihallucination_dataset/resolve/main/antihallucination.jsonl -o antihallucination.jsonl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbvSr84JG0A2",
        "outputId": "4be14d9d-48f9-4122-b84c-40cc1fa31bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  762k  100  762k    0     0  2047k      0 --:--:-- --:--:-- --:--:-- 2044k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = together.Files.check(file=\"antihallucination.jsonl\")\n",
        "resp\n",
        "#togethercomputer/RedPajama-INCITE-7B-Base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVyxvuA4H4wn",
        "outputId": "26acbe40-6cef-4692-c0e8-c030e6ec69c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'is_check_passed': True,\n",
              " 'model_special_tokens': 'we are not yet checking end of sentence tokens for this model',\n",
              " 'file_present': 'File found',\n",
              " 'file_size': 'File size 0.001 GB',\n",
              " 'num_samples': 238}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "together.Files.upload(file=\"antihallucination.jsonl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h__6fwSDIDEM",
        "outputId": "c2b5510a-6a7b-4afb-8ebe-ad157d60f231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Uploading antihallucination.jsonl: 100%|██████████| 763k/763k [00:00<00:00, 1.21MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'filename': 'antihallucination.jsonl',\n",
              " 'id': 'file-9fd1f11f-5d92-428c-9781-74cc3cc67c20',\n",
              " 'object': 'file',\n",
              " 'report_dict': {'is_check_passed': True,\n",
              "  'model_special_tokens': 'we are not yet checking end of sentence tokens for this model',\n",
              "  'file_present': 'File found',\n",
              "  'file_size': 'File size 0.001 GB',\n",
              "  'num_samples': 238}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start the finetuning.\n",
        "Note the id returned. We will be using that."
      ],
      "metadata": {
        "id": "abDKTalBcMJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp = together.Finetune.create(\n",
        "  training_file = 'file-f102d272-e770-461e-833a-e08615a5bee5',\n",
        "  model = 'togethercomputer/RedPajama-INCITE-Chat-3B-v1',\n",
        "  n_epochs = 3,\n",
        "  n_checkpoints = 1,\n",
        "  batch_size = 4,\n",
        "  learning_rate = 1e-5,\n",
        "  suffix = 'my-demo-finetune',\n",
        ")\n",
        "\n",
        "fine_tune_id = resp['id']\n",
        "print(resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "x6yrXs2VJTHf",
        "outputId": "c8c4947e-4255-442d-a383-41432f4c5a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31;1m03-03-2024 05:57:53 - together.finetune - CRITICAL - training_file refers to a file identifier of an uploaded training file, not a local file path. A list of uploaded files and file identifiers can be retrieved with `together.Files.list()` Python API or $ together files list` CLI. A training file can be uploaded using `together.Files.upload(file ='/path/to/file')Python API or `$ together files upload <FILE_PATH>` CLI. (finetune.py:124)\u001b[0m\n",
            "CRITICAL:together.finetune:training_file refers to a file identifier of an uploaded training file, not a local file path. A list of uploaded files and file identifiers can be retrieved with `together.Files.list()` Python API or $ together files list` CLI. A training file can be uploaded using `together.Files.upload(file ='/path/to/file')Python API or `$ together files upload <FILE_PATH>` CLI.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileTypeError",
          "evalue": "training_file refers to a file identifier of an uploaded training file, not a local file path. A list of uploaded files and file identifiers can be retrieved with `together.Files.list()` Python API or $ together files list` CLI. A training file can be uploaded using `together.Files.upload(file ='/path/to/file')Python API or `$ together files upload <FILE_PATH>` CLI.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileTypeError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bf0abd59ae4a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m resp = together.Finetune.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mtraining_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'file-f102d272-e770-461e-833a-e08615a5bee5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'togethercomputer/RedPajama-INCITE-Chat-3B-v1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mn_checkpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/together/finetune.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, training_file, model, n_epochs, n_checkpoints, batch_size, learning_rate, suffix, estimate_price, wandb_api_key, confirm_inputs)\u001b[0m\n\u001b[1;32m    123\u001b[0m             )\n\u001b[1;32m    124\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_file_feedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mtogether\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_file_feedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mestimate_price\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileTypeError\u001b[0m: training_file refers to a file identifier of an uploaded training file, not a local file path. A list of uploaded files and file identifiers can be retrieved with `together.Files.list()` Python API or $ together files list` CLI. A training file can be uploaded using `together.Files.upload(file ='/path/to/file')Python API or `$ together files upload <FILE_PATH>` CLI."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZYcFqVCJvME",
        "outputId": "46a03bff-547c-4537-9d34-0b9030ea6b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'training_file': 'file-f102d272-e770-461e-833a-e08615a5bee5',\n",
              " 'validation_file': '',\n",
              " 'model_output_name': 'balaji@mitrarobot.com/RedPajama-INCITE-Chat-3B-v1-my-demo-finetune-2024-03-01-02-27-24',\n",
              " 'model_output_path': 's3://together-dev/finetune/65a21caab4d260b5d9ecd29c/balaji@mitrarobot.com/RedPajama-INCITE-Chat-3B-v1-my-demo-finetune-2024-03-01-02-27-24/ft-3589849c-599f-40f3-91cc-3d31fa5e8b9d',\n",
              " 'Suffix': 'my-demo-finetune',\n",
              " 'model': 'togethercomputer/RedPajama-INCITE-Chat-3B-v1',\n",
              " 'n_epochs': 3,\n",
              " 'n_checkpoints': 1,\n",
              " 'batch_size': 4,\n",
              " 'learning_rate': 1e-05,\n",
              " 'eval_steps': 0,\n",
              " 'user_id': '65a21caab4d260b5d9ecd29c',\n",
              " 'lora': False,\n",
              " 'lora_r': 8,\n",
              " 'lora_alpha': 8,\n",
              " 'lora_dropout': 0,\n",
              " 'staring_epoch': 0,\n",
              " 'training_offset': 0,\n",
              " 'checkspoint_path': '',\n",
              " 'random_seed': '',\n",
              " 'created_at': '2024-03-01T02:27:24.356Z',\n",
              " 'updated_at': '2024-03-01T02:27:24.356Z',\n",
              " 'status': 'pending',\n",
              " 'owner_address': '0x5ba793d39b138b27366a9284671222c35088a73e',\n",
              " 'id': 'ft-3589849c-599f-40f3-91cc-3d31fa5e8b9d',\n",
              " 'job_id': '',\n",
              " 'token_count': 0,\n",
              " 'param_count': 0,\n",
              " 'total_price': 0,\n",
              " 'epochs_completed': 0,\n",
              " 'events': [{'object': 'fine-tune-event',\n",
              "   'created_at': '2024-03-01T02:27:24.356Z',\n",
              "   'level': '',\n",
              "   'message': 'Fine tune request created',\n",
              "   'type': 'JOB_PENDING',\n",
              "   'param_count': 0,\n",
              "   'token_count': 0,\n",
              "   'wandb_url': '',\n",
              "   'checkpoint_path': '',\n",
              "   'model_path': '',\n",
              "   'training_offset': 0,\n",
              "   'hash': ''}],\n",
              " 'queue_depth': 0,\n",
              " 'wandb_key': '',\n",
              " 'wandb_project_name': '',\n",
              " 'wandb_url': '',\n",
              " 'enable_checkpoints': False,\n",
              " 'internal_flags': '',\n",
              " 'UsedModelName': '',\n",
              " 'TrainingFileNumLines': 0,\n",
              " 'TrainingFileSize': 781040,\n",
              " 'job_stats': {'FtUserTime': '',\n",
              "  'FtSysTime': '',\n",
              "  'FtMaxRss': 0,\n",
              "  'FtMinPgFlt': 0,\n",
              "  'FtMajPgFlt': 0,\n",
              "  'FtInBlock': 0,\n",
              "  'FtOutBlock': 0,\n",
              "  'FtNvCsw': 0,\n",
              "  'FtNivCsw': 0}}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(together.Finetune.retrieve(fine_tune_id='ft-997f4ef1-9258-4748-ace2-ddad8e5bc245')) # pending, running, completed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLvYfSlxKdIs",
        "outputId": "a8f952dc-6fb4-401f-c0fe-fe5873ca97b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'training_file': 'file-f102d272-e770-461e-833a-e08615a5bee5', 'validation_file': '', 'model_output_name': 'balaji@mitrarobot.com/RedPajama-INCITE-Chat-3B-v1-my-demo-finetune-2024-02-06-02-01-21', 'model_output_path': 's3://together-dev/finetune/65a21caab4d260b5d9ecd29c/balaji@mitrarobot.com/RedPajama-INCITE-Chat-3B-v1-my-demo-finetune-2024-02-06-02-01-21/ft-997f4ef1-9258-4748-ace2-ddad8e5bc245', 'Suffix': 'my-demo-finetune', 'model': 'togethercomputer/RedPajama-INCITE-Chat-3B-v1', 'n_epochs': 3, 'n_checkpoints': 1, 'batch_size': 4, 'learning_rate': 1e-05, 'user_id': '65a21caab4d260b5d9ecd29c', 'lora': False, 'lora_r': 8, 'lora_alpha': 8, 'lora_dropout': 0, 'staring_epoch': 0, 'training_offset': 0, 'checkspoint_path': '', 'random_seed': '', 'created_at': '2024-02-06T02:01:21.055Z', 'updated_at': '2024-02-06T02:05:38.333Z', 'status': 'uploading', 'owner_address': '0x5ba793d39b138b27366a9284671222c35088a73e', 'id': 'ft-997f4ef1-9258-4748-ace2-ddad8e5bc245', 'job_id': '12525', 'token_count': 178643, 'param_count': 2775864320, 'total_price': 5000000000, 'epochs_completed': 3, 'events': [{'object': 'fine-tune-event', 'created_at': '2024-02-06T02:01:21.055Z', 'level': '', 'message': 'Fine tune request created', 'type': 'JOB_PENDING', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': ''}, {'object': 'fine-tune-event', 'created_at': '2024-02-06T02:01:24Z', 'level': 'Info', 'message': 'Job started at Mon Feb  5 18:01:23 PST 2024', 'type': 'JOB_START', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-6329461308498025369'}, {'object': 'fine-tune-event', 'created_at': '2024-02-06T02:02:34Z', 'level': 'Info', 'message': 'Model data downloaded for togethercomputer/RedPajama-INCITE-Chat-3B-v1 at Mon Feb  5 18:02:33 PST 2024', 'type': 'MODEL_DOWNLOAD_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '5610423705922763038'}, {'object': 'fine-tune-event', 'created_at': '2024-02-06T02:02:36Z', 'level': 'Info', 'message': 'Training data downloaded for togethercomputer/RedPajama-INCITE-Chat-3B-v1 at Mon Feb  5 18:02:36 PST 2024', 'type': 'TRAINING_DATA_DOWNLOAD_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-5261860802664890783'}, {'object': 'fine-tune-event', 'created_at': '2024-02-06T02:03:10Z', 'level': 'Info', 'message': 'Training started for model /work/job-ft-997f4ef1-9258-4748-ace2-ddad8e5bc245/model', 'type': 'TRAINING_START', 'param_count': 2775864320, 'token_count': 178643, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-2738100526567562104'}, {'object': 'fine-tune-event', 'created_at': '2024-02-06T02:03:37Z', 'level': 'Info', 'message': 'Epoch completed, at step 22', 'type': 'EPOCH_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-1672485830921663722'}, {'object': 'fine-tune-event', 'created_at': '2024-02-06T02:03:59Z', 'level': 'Info', 'message': 'Epoch completed, at step 44', 'type': 'EPOCH_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-764654373642459026'}, {'object': 'fine-tune-event', 'created_at': '2024-02-06T02:04:23Z', 'level': 'Info', 'message': 'Epoch completed, at step 66', 'type': 'EPOCH_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-726607133383531856'}, {'object': 'fine-tune-event', 'created_at': '2024-02-06T02:05:06Z', 'level': 'Info', 'message': 'Training completed for togethercomputer/RedPajama-INCITE-Chat-3B-v1 at Mon Feb  5 18:05:06 PST 2024', 'type': 'TRAINING_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '6825565871350778911'}, {'object': 'fine-tune-event', 'created_at': '2024-02-06T02:05:30Z', 'level': 'Info', 'message': 'Compressing output model', 'type': 'COMPRESSING_MODEL', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '-5157976410885973588'}, {'object': 'fine-tune-event', 'created_at': '2024-02-06T02:05:37Z', 'level': 'Info', 'message': 'Model compression complete', 'type': 'MODEL_COMPRESSION_COMPLETE', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '5880811708908732253'}, {'object': 'fine-tune-event', 'created_at': '2024-02-06T02:05:37Z', 'level': 'Info', 'message': 'Uploading output model', 'type': 'MODEL_UPLOADING', 'param_count': 0, 'token_count': 0, 'wandb_url': '', 'checkpoint_path': '', 'model_path': '', 'training_offset': 0, 'hash': '2622159224635764188'}], 'queue_depth': 0, 'wandb_key': '', 'wandb_project_name': '', 'wandb_url': '', 'enable_checkpoints': False, 'internal_flags': '', 'UsedModelName': '', 'TrainingFileNumLines': 0, 'TrainingFileSize': 781040, 'job_stats': {'FtUserTime': '', 'FtSysTime': '', 'FtMaxRss': 0, 'FtMinPgFlt': 0, 'FtMajPgFlt': 0, 'FtInBlock': 0, 'FtOutBlock': 0, 'FtNvCsw': 0, 'FtNivCsw': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and setup the model\n",
        "In Together  ai dahsboard: https://api.together.xyz/playground/jobs check the status and once the job is completed, download it."
      ],
      "metadata": {
        "id": "XCIF2HfNcYKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "together.Finetune.download(\n",
        "    fine_tune_id=\"ft-997f4ef1-9258-4748-ace2-ddad8e5bc245\",\n",
        "    output = \"anti-hallucination-model.tar.zst\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "vspAwuoOOujZ",
        "outputId": "83613844-e8f1-4dcc-e1fd-1c9f5d937381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading weights from https://api.together.xyz/api/finetune/downloadfinetunefile?ft_id=ft-997f4ef1-9258-4748-ace2-ddad8e5bc245...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading anti-hallucination-model.tar.zst: 100%|██████████| 5.10G/5.10G [03:22<00:00, 25.2MiB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'anti-hallucination-model.tar.zst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install zstd\n",
        "!zstd -d anti-hallucination-model.tar.zst\n",
        "!mkdir -p /my-model\n",
        "!tar -xvf anti-hallucination-model.tar -C /my-model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE94ECaBPRiV",
        "outputId": "a8e75751-2aee-4f57-aa0e-d08d47f343fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "zstd is already the newest version (1.4.8+dfsg-3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "anti-hallucination-model.tar.zst: 5553940480 bytes \n",
            "./\n",
            "./tokenizer_config.json\n",
            "./special_tokens_map.json\n",
            "./model.safetensors.index.json\n",
            "./model-00001-of-00002.safetensors\n",
            "./model-00002-of-00002.safetensors\n",
            "./generation_config.json\n",
            "./tokenizer.json\n",
            "./config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/my-model\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  \"/my-model\",\n",
        "  trust_remote_code=True,\n",
        ").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "1283cf2e89a74f9e986ec867d3b70fb5",
            "4cec98fed4f24d72a46da22bd64a3397",
            "2b579f8ed21049dbb566c66da349456e",
            "aad85dfe33ee48ad8dffe702d99f165f",
            "1fb0d7f29405491296f2ce8503ff16e1",
            "de49ba4f1183410fa42bedb8b4334ef0",
            "5d5c3eb1d8594dfe885406404294e11c",
            "a53c3494eeda46439c693f02a1d4bbc9",
            "28e9f18994144ca8a5e924b88f564ca0",
            "d23901785d8149878af815d56585bc79",
            "0ad3a3ae24544bb9adcbc272f8e071e3"
          ]
        },
        "id": "MYSP_mQpQen8",
        "outputId": "9e4ec55d-a150-4ac6-ccf2-f5e2c33330fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1283cf2e89a74f9e986ec867d3b70fb5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(input):\n",
        "  input_ids = tokenizer.encode(input, return_tensors=\"pt\")\n",
        "  output = model.generate(input_ids.to(device), max_length=100, temperature=0.1)\n",
        "  return tokenizer.decode(output[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "6VLciOvQZsYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PT model says: Kirill Karabits is a British conductor and music director of the Los Angeles Philharmonic.\n",
        "get_completion(\"Kirill Karabits\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "DY85Olo1Qtjh",
        "outputId": "e62513db-964a-476c-8db6-7262d2c87018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Kirill Karabits, the conductor of the National Symphony Orchestra of Ukraine, is a Ukrainian conductor and composer. He is the son of the conductor and composer Mykola Karabits. He studied at the Lysenko Music School in Kiev, the Kiev Conservatory, and the Royal Northern College of Music in Manchester. He has held the position of Music Director of the National Symphony Orchestra of Ukraine since 2015. He has also held the position of Music Director of the Royal Northern College'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(\"Modibo Adamu\")\n",
        "#PT model says Modibo Adamu is a Nigerian politician and lawyer who served as the Attorney General and Minister of Justice of Nigeria from 2015 to 2019. He previously served as the Attorney General of the Federation and Minister of Justice from 1999 to 2007."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "xQ4aLNWcaAEC",
        "outputId": "d8bfd8d3-9c58-4279-fda3-02c5d7ad2b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Modibo Adamu, a Fulani leader, was the first to be appointed as a traditional ruler in the state. He was appointed as the Emir of Kano in 1859. Adamu was succeeded by his son, Muhammadu Sunusi, who was appointed as the Emir of Kano in 1879. Sunusi was succeeded by his son, Muhammadu Sunusi II, who was appointed as the Emir of Kano in 1887. Sunusi II was succeeded by his son, Muhammadu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(\"Political party of Tathagata Satpathy\")\n",
        "#PT model says Bharatiya Janata Party"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "HP-shMcSa649",
        "outputId": "bba93f22-1ac6-49b5-c62c-828370c0382d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Political party of Tathagata Satpathy\\n\\nTathagata Satpathy (born 28 April 1956) is an Indian politician and a member of the Biju Janata Dal (BJD) party. He is a former Member of Parliament in the Lok Sabha from the Biju Janata Dal (BJD) party. Satpathy was born in the village of Kakamadugu in the district of Ganjam in the Indian state of Odisha. He is a graduate of'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning a larger dataset\n",
        "### Let's build a strong legal bot"
      ],
      "metadata": {
        "id": "Ha-XZjeabW3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/Constitution_Of_India_Train.jsonl\"\n",
        "resp = together.Files.check(file=file_name)\n",
        "resp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRNxDyvmkOjp",
        "outputId": "33ff529f-d19d-49b7-bb94-eb1c7469feea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'is_check_passed': False,\n",
              " 'model_special_tokens': 'we are not yet checking end of sentence tokens for this model',\n",
              " 'file_present': 'File found',\n",
              " 'file_size': 'File size 0.007 GB',\n",
              " 'text_field': 'No \"text\" field was found on line 3036 of the the input file.Expected format: {\"text\":\"my sample string\"}.see https://docs.together.ai/docs/fine-tuning for more information.{\"instruction\": \"Discuss the potential impact of the given case on Indian law enforcement agencies.\", \"input\": \"Case Citation: R. Rajagopal vs State Of T.N, (1994) 6 SCC 632\", \"output\": \"The decision in the case of R. Rajagopal vs State Of T.N can have several potential impacts on Indian law enforcement agencies. Here are some key points to consider:\\\\n\\\\n1. Strengthening of Right to Privacy: The case established that the right to privacy is a fundamental right under Article 21 of the Constitution. This recognition of privacy as a fundamental right can impact law enforcement agencies by imposing limitations on their investigative practices. They may need to ensure that their actions and investigations respect the privacy rights of individuals.\\\\n\\\\n2. Balancing Privacy and Law Enforcement: While recognizing the right to privacy, the court also acknowledged certain exceptions to this right, such as public records and acts of public officials related to their duties. This balancing approach ensures that law enforcement agencies can continue to carry out their duties while respecting privacy rights.\\\\n\\\\n3. Need for Proper Authorization: The case highlighted the importance of obtaining proper authorization before publishing or disclosing someone\\'s private life. This can have implications for law enforcement agencies when it comes to sharing information or evidence related to ongoing investigations. They may need to ensure that proper legal procedures are followed to protect the privacy of individuals involved.\\\\n\\\\n4. Accountability and Damages: The court emphasized that unauthorized publication of private life violates the right to privacy and can be remedied through civil action for damages. This can serve as a reminder to law enforcement agencies to handle personal information and evidence with care, ensuring that they do not infringe upon an individual\\'s privacy rights. It may also encourage individuals to seek legal remedies if their privacy is violated by law enforcement agencies.\\\\n\\\\n5. Training and Awareness: The case brings attention to the importance of training and awareness among law enforcement agencies regarding privacy rights. It may prompt agencies to provide training to their personnel on privacy laws and regulations, ensuring that they are well-informed about the boundaries and limitations when it comes to handling personal information.\\\\n\\\\nOverall, the decision in the R. Rajagopal case can lead to a more privacy-conscious approach within Indian law enforcement agencies. It can promote a better understanding of privacy rights and the need to balance them with the responsibilities of law enforcement. This can ultimately contribute to a more accountable and respectful law enforcement system in India.\", \"prompt\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\\\n\\\\n### Instruction:\\\\nDiscuss the potential impact of the given case on Indian law enforcement agencies.\\\\n\\\\n### Input:\\\\nCase Citation: R. Rajagopal vs State Of T.N, (1994) 6 SCC 632\\\\n\\\\n### Response:\"}\\n',\n",
              " 'load_json': 'File should be a valid jsonlines (.jsonl) with a json in each line.Example of valid json: {\"text\":\"my sample string\"}Valid json not found in one or more lines in file.see https://docs.together.ai/docs/fine-tuning.The first line where this occur is line 3037, where 1 is the first line.{\"instruction\": \"Develop a hypothetical question that could be raised in parliament based on the provided case.\", \"input\": \"R. Rajagopal vs State Of T.N, (1994) 6 SCC 632\", \"output\": \"What steps is the government taking to ensure the protection of an individual\\'s right to pr'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This dataset is not in a format to be directly finetuned"
      ],
      "metadata": {
        "id": "p7Yhfv1ZniBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "input_jsonl_path = \"Constitution_Of_India_Train.jsonl\"\n",
        "output_jsonl_path = 'processed_law_training.jsonl'\n",
        "with open(input_jsonl_path, 'r') as infile, open(output_jsonl_path, 'w') as outfile:\n",
        "  for line in infile:\n",
        "        try:\n",
        "            json_obj = json.loads(line)\n",
        "\n",
        "            # Construct the combined text\n",
        "            combined_text = f\"<human>:\\n{json_obj['instruction']}\\n\\n### Prompt:\\n{json_obj['prompt']}\\n\\n### Input:\\n{json_obj['input']}\\n\\n<bot>:\\n{json_obj['output']}\"\n",
        "\n",
        "            # Prepare the new JSON object with the combined text\n",
        "            output_json_obj = {'text': combined_text}\n",
        "\n",
        "            # Write the new JSON object to the output file\n",
        "            outfile.write(json.dumps(output_json_obj) + '\\n')\n",
        "        except KeyError as e:\n",
        "            print(f\"Missing field in data: {e}\")\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Could not decode a line as JSON.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdO6eNIFnn0i",
        "outputId": "f14571eb-9e65-40c9-9bef-c821a0604f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing field in data: 'input'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "together.Files.upload(file=\"processed_law_training.jsonl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofhR2hyVqBS-",
        "outputId": "65cea032-6b51-45be-dc93-6389926403ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Uploading processed_law_training.jsonl: 100%|██████████| 8.66M/8.66M [00:00<00:00, 10.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'filename': 'processed_law_training.jsonl',\n",
              " 'id': 'file-cc2b3901-24d8-41c7-8e20-442e0bb801f0',\n",
              " 'object': 'file',\n",
              " 'report_dict': {'is_check_passed': True,\n",
              "  'model_special_tokens': 'we are not yet checking end of sentence tokens for this model',\n",
              "  'file_present': 'File found',\n",
              "  'file_size': 'File size 0.008 GB',\n",
              "  'num_samples': 4393}}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = together.Finetune.create(\n",
        "  training_file = 'file-c249b7a7-60d4-4ce4-b7d7-6f8f90470f34',\n",
        "  model = 'togethercomputer/RedPajama-INCITE-Chat-3B-v1',\n",
        "  n_epochs = 3,\n",
        "  n_checkpoints = 1,\n",
        "  batch_size = 4,\n",
        "  learning_rate = 1e-5,\n",
        "  suffix = 'law-finetuning',\n",
        ")\n",
        "\n",
        "fine_tune_id = resp['id']\n",
        "resp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2nd2Y7RqH2V",
        "outputId": "46572994-7a18-43cc-fda1-e52de859dbac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'training_file': 'file-c249b7a7-60d4-4ce4-b7d7-6f8f90470f34',\n",
              " 'validation_file': '',\n",
              " 'model_output_name': 'balaji@mitrarobot.com/RedPajama-INCITE-Chat-3B-v1-law-finetuning-2024-03-01-02-32-39',\n",
              " 'model_output_path': 's3://together-dev/finetune/65a21caab4d260b5d9ecd29c/balaji@mitrarobot.com/RedPajama-INCITE-Chat-3B-v1-law-finetuning-2024-03-01-02-32-39/ft-42261e6c-7c80-4aa8-af4f-7b9c20a71e04',\n",
              " 'Suffix': 'law-finetuning',\n",
              " 'model': 'togethercomputer/RedPajama-INCITE-Chat-3B-v1',\n",
              " 'n_epochs': 3,\n",
              " 'n_checkpoints': 1,\n",
              " 'batch_size': 4,\n",
              " 'learning_rate': 1e-05,\n",
              " 'eval_steps': 0,\n",
              " 'user_id': '65a21caab4d260b5d9ecd29c',\n",
              " 'lora': False,\n",
              " 'lora_r': 8,\n",
              " 'lora_alpha': 8,\n",
              " 'lora_dropout': 0,\n",
              " 'staring_epoch': 0,\n",
              " 'training_offset': 0,\n",
              " 'checkspoint_path': '',\n",
              " 'random_seed': '',\n",
              " 'created_at': '2024-03-01T02:32:39.207Z',\n",
              " 'updated_at': '2024-03-01T02:32:39.207Z',\n",
              " 'status': 'pending',\n",
              " 'owner_address': '0x5ba793d39b138b27366a9284671222c35088a73e',\n",
              " 'id': 'ft-42261e6c-7c80-4aa8-af4f-7b9c20a71e04',\n",
              " 'job_id': '',\n",
              " 'token_count': 0,\n",
              " 'param_count': 0,\n",
              " 'total_price': 0,\n",
              " 'epochs_completed': 0,\n",
              " 'events': [{'object': 'fine-tune-event',\n",
              "   'created_at': '2024-03-01T02:32:39.207Z',\n",
              "   'level': '',\n",
              "   'message': 'Fine tune request created',\n",
              "   'type': 'JOB_PENDING',\n",
              "   'param_count': 0,\n",
              "   'token_count': 0,\n",
              "   'wandb_url': '',\n",
              "   'checkpoint_path': '',\n",
              "   'model_path': '',\n",
              "   'training_offset': 0,\n",
              "   'hash': ''}],\n",
              " 'queue_depth': 0,\n",
              " 'wandb_key': '',\n",
              " 'wandb_project_name': '',\n",
              " 'wandb_url': '',\n",
              " 'enable_checkpoints': False,\n",
              " 'internal_flags': '',\n",
              " 'UsedModelName': '',\n",
              " 'TrainingFileNumLines': 0,\n",
              " 'TrainingFileSize': 9077033,\n",
              " 'job_stats': {'FtUserTime': '',\n",
              "  'FtSysTime': '',\n",
              "  'FtMaxRss': 0,\n",
              "  'FtMinPgFlt': 0,\n",
              "  'FtMajPgFlt': 0,\n",
              "  'FtInBlock': 0,\n",
              "  'FtOutBlock': 0,\n",
              "  'FtNvCsw': 0,\n",
              "  'FtNivCsw': 0}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The API returns a PENDING status message that contains the job ID. Once the fine_tune job completes, we can retrieve the updated weights from Together's training instance."
      ],
      "metadata": {
        "id": "ZAqXl9jngt6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "together.Finetune.download(\n",
        "    fine_tune_id=\"ft-713f7054-51fe-439a-94e5-525bdde87eea\",\n",
        "    output = \"law-model.tar.zst\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "oKCrPDcfqkfR",
        "outputId": "d2680e83-bf73-4d41-87f2-a86580747f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading weights from https://api.together.xyz/api/finetune/downloadfinetunefile?ft_id=ft-713f7054-51fe-439a-94e5-525bdde87eea...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading law-model.tar.zst: 100%|██████████| 5.10G/5.10G [01:18<00:00, 65.1MiB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'law-model.tar.zst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: We have downloaded a 5.1GB compressed file containing the full weights of RedPajama incite 3B model which have been adjusted to accommodate the new knowledge from our SFT dataset. This process is called full fine-tuning. In another notebook, we will show you another efficient method called Partial fine-tuning or parameter efficient fine-tuning (PEFT)."
      ],
      "metadata": {
        "id": "Mbjid4mUfUe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip the model package containing weights and config\n",
        "!apt-get install zstd\n",
        "!zstd -d law-model.tar.zst\n",
        "!mkdir -p /content/law-model\n",
        "!tar -xvf law-model.tar -C /content/law-model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FekSH60GrD3E",
        "outputId": "56ab5a2f-2f3e-4577-9453-cf217bd06ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  zstd\n",
            "0 upgraded, 1 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 603 kB of archives.\n",
            "After this operation, 1,695 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 zstd amd64 1.4.8+dfsg-3build1 [603 kB]\n",
            "Fetched 603 kB in 0s (1,647 kB/s)\n",
            "Selecting previously unselected package zstd.\n",
            "(Reading database ... 121747 files and directories currently installed.)\n",
            "Preparing to unpack .../zstd_1.4.8+dfsg-3build1_amd64.deb ...\n",
            "Unpacking zstd (1.4.8+dfsg-3build1) ...\n",
            "Setting up zstd (1.4.8+dfsg-3build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "law-model.tar.zst   : 5553940480 bytes \n",
            "./\n",
            "./tokenizer_config.json\n",
            "./special_tokens_map.json\n",
            "./model.safetensors.index.json\n",
            "./model-00001-of-00002.safetensors\n",
            "./model-00002-of-00002.safetensors\n",
            "./generation_config.json\n",
            "./tokenizer.json\n",
            "./config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HF🤗 Transformers expects the weights and config file in a single directory and the name of the directory can be used to load the model. Note that the weights are in a format called [safetensors](https://huggingface.co/docs/safetensors/en/index) which is considered better than pickle. In a single line of code, the Transformers library can load the model weights, quantize them if required and put the model in [eval mode](https://discuss.pytorch.org/t/where-to-use-model-eval/89200)."
      ],
      "metadata": {
        "id": "JAmyUNMLhp0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"law-model\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  \"law-model\",\n",
        "  trust_remote_code=True,\n",
        ").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "53101483739f487bb495d85e69753467",
            "ecefaf97315d49ddb2c4c10e25ef009c",
            "98aa77db4be343b98c226164158b4f99",
            "fb8f1cabc6614cae97041576f6058ceb",
            "723d702b8dd24bc4ae561565c16fe3d2",
            "b6babd38e9204d2d88a34a8ad593b6a3",
            "0d958d07676b46edac59aebea0d3480a",
            "5ef3453c23c44c3688609863eb5541a3",
            "b87fc7f13f114334ae98ee786a7c342d",
            "ec0cfc8f9257408aa0317596f08b968b",
            "74564ed0749749e9ab083601c2d5d7db"
          ]
        },
        "id": "S2u-jWQ_rU6-",
        "outputId": "d90f98ac-ae34-4264-cb0b-da029f255a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53101483739f487bb495d85e69753467"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(input):\n",
        "  input_ids = tokenizer.encode(input, return_tensors=\"pt\")\n",
        "  output = model.generate(input_ids.to(device), max_length=512, temperature=0.1)\n",
        "  return tokenizer.decode(output[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "f5ENOzRCs7iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(\"Draft a hypothetical legal advice for a client based on the outcome of the provided case. entral Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "3BxRKhAEwVIx",
        "outputId": "c4262e18-7efc-4065-d332-84549f3d9a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Draft a hypothetical legal advice for a client based on the outcome of the provided case. entral Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278.\\n\\n### Input:\\nEntral Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278.\\n\\n<bot>:\\nBased on the outcome of the mentioned case, the following hypothetical legal advice can be provided to a client:\\n\\nDear Client,\\n\\nAfter carefully analyzing the case of Entral Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., it is evident that the Supreme Court upheld the constitutional validity of the service rule 9(i) allowing termination of permanent employees without assigning any reason under the right to equality under Article 14.\\n\\nConsidering this outcome, it is important for you to understand that the court has deemed the service rule as constitutional and has upheld the validity of the company's termination of your employment. Therefore, it is crucial to assess the potential implications of this decision on your case.\\n\\nFirstly, it is important to note that the court has not found any evidence of arbitrary termination or violation of principles of natural justice. Therefore, it can be argued that the termination was fair and within the bounds of the service rule.\\n\\nSecondly, it is important to understand that the court has not found any evidence of any violation of your fundamental rights under Article 21. Therefore, it can be argued that the termination did not amount to a deprivation of your rights.\\n\\nThirdly, it is important to consider that the court has not found any evidence of any mala fide intention or motive behind the termination. Therefore, it can be argued that the termination was not done in bad faith.\\n\\nBased on the outcome of this case, it is advisable for you to review your employment contract and assess whether any amendments or clarifications are necessary to reflect the new legal status of the service rule. It is also important for you to consult with a legal professional to understand your rights and options in light of this decision.\\n\\nPlease feel free to reach out to me if you have any further questions or require additional assistance. I am here to support you throughout this process.\\n\\nYours sincerely,\\n[Your Name]\\n[Your Law Firm/Organization]<human>:\\nDiscuss the potential\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(\"Explain how Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly is relevant to the digital law\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "tOuXYvdeyLDj",
        "outputId": "d5837ce1-f7af-43cb-ca2d-b49afd24601d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Explain how Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly is relevant to the digital law context.\\n\\n### Prompt:\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nExplain how Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly is relevant to the digital law context.\\n\\n### Input:\\nThe case of Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278, Supreme Court of India\\n\\n### Response:\\n\\n### Input:\\nThe case of Central Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr., 1986 AIR 1571, 1986 SCR (2) 278, Supreme Court of India\\n\\n<bot>:\\nCentral Inland Water Transport Corporation Ltd. vs Brojo Nath Ganguly & Anr. is a significant case in the context of digital law in India, particularly in relation to the right to equality under Article 14 and the prohibition of discrimination on grounds of religion, race, caste, sex, or place of birth under Article 15(1) of the Constitution. The case deals with the validity of a service rule allowing termination of employment without reason, which is argued to be discriminatory and violative of Article 14.   In the digital law context, this case can be relevant in the following ways:  1. Recognition of the Right to Equality: The case reaffirms the constitutional right to equality under Article 14 and emphasizes that it includes the right to equal treatment without discrimination on similar grounds. This recognition can guide the interpretation and application of Article 14 in the digital law context, where similar discrimination claims may arise.  2. Protection Against Discrimination: The case upholds the prohibition of discrimination on grounds of religion, race, caste, sex, or place of birth as valid under Article 15(1). In the digital law context, this can be relevant in cases where discrimination based on these factors is alleged or occurs.  3. Service Rule Validity: The case examines the validity of a service rule allowing termination of employment without reason under right to equality. The court held that such a rule is arbitrary and violative of Article 14. In the digital law context, this can be relevant in cases where service rules or policies are challenged on similar grounds.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(\"Formulate a potential public interest litigation against the government's right to operate religious places.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7NGUx62by3T6",
        "outputId": "11c12999-1f2d-45f5-f85f-623db3dad222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Formulate a potential public interest litigation against the government's right to operate religious places.\\n\\n### Input:\\nThe case of Minerva Mills Ltd. & Ors vs Union Of India & Ors\\n\\n### Response:\\n\\n### Input:\\nThe case of Minerva Mills Ltd. & Ors vs Union Of India & Ors\\n\\n<bot>:\\nA potential public interest litigation (PIL) that can be formulated against the government's right to operate religious places is as follows:\\n\\nTitle: Challenging the Right to Operate Religious Places\\n\\nParties:\\n1. Petitioners: General Public\\n2. Respondents: Government of India and its agencies\\n\\nSummary of the Case:\\nThis PIL challenges the constitutional validity of the government's right to operate religious places. It argues that this right infringes upon the fundamental rights of the petitioners, who are individuals and religious institutions, to practice and manage their religious affairs.\\n\\nCause of Action:\\nThe cause of action for this PIL arises from the government's interference in the management and administration of religious places, which violates the freedom of religion guaranteed under Articles 25 and 26 of the Constitution.\\n\\nReliefs Sought:\\nThe petitioners seek the following reliefs:\\n1. Declare the government's right to operate religious places as unconstitutional and violative of Articles 25 and 26 of the Constitution.\\n2. Direct the government to withdraw its interference in the management and administration of religious places and allow religious institutions to manage their affairs without undue government interference.\\n3. Establish a regulatory body to oversee the functioning of religious places and prevent maladministration.\\n4. Pass any other order that the court deems fit in the interest of justice.\\n\\nLegal Grounds:\\nThe PIL relies on the following legal grounds:\\n1. Violation of Freedom of Religion: The right to manage religious affairs is an essential aspect of the freedom of religion guaranteed under Articles 25 and 26 of the Constitution. The government's interference in the management and administration of religious places infringes upon this freedom.\\n2. Violation of Article 14: The right to manage religious affairs is also governed by Article 14 of the Constitution, which guarantees the right to equality before the law. The government's interference in the management of religious places discriminates against the petitioners, who are religious institutions, in violation of Article 14.\\n3. Violation of Article 19(1)(g): The right to manage religious affairs is also protected under Article 19(1)(g) of the Constitution, which guarantees the right to practice and propagate one's religion. The government's interference in the management of religious places violates this fundamental right.\\n\\nPrayer:\\nThe petitioners pray for the court to declare the government's right to operate religious places as unconstitutional and violative of Articles 25 and 26 of the Constitution. They also seek appropriate directions to the government to withdraw its interference in the management and administration of religious places and establish a regulatory body to prevent maladministration.\\n\\nNote: This is a hypothetical formulation of a PIL based on the provided case. Actual PILs need to be drafted by legal professionals based on the specific facts and circumstances of the case.<human>:\\nAnswer the Question in the most accurate way possible.\\n\\n### Prompt:\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAnswer the Question in the most accurate way possible.\\n\\n### Input:\\nWhat is the role of the Governor in the administration of tribal areas?\\n\\n### Response:\\n\\n### Input:\\nWhat is the role of the Governor in the administration of tribal areas?\\n\\n<bot>:\\nThe Governor plays a crucial role in the administration of tribal areas under the Sixth Schedule. The Governor has the authority to divide areas inhabited by different Scheduled Tribes into autonomous regions, include or exclude any area from the autonomous districts, create new autonomous districts, alter the name or boundaries of any autonomous district, and make rules for the constitution of District Councils and Regional Councils. Additionally, the Governor has the authority to confer powers under the Constitution on District Councils and Regional Councils, and make laws for the administration of autonomous areas, including laws on subjects listed in the State List under the Seventh Schedule.<human>:\\nAnswer the Question in the most accurate way possible.\\n\\n### Prompt:\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAnswer the Question in the most accurate way possible.\\n\\n### Input:\\nWhat is the role of the Governor in the administration of tribal areas?\\n\\n### Response:\\n\\n### Input:\\nWhat is the role of the Governor in the administration of tribal areas?\\n\\n<bot>:\\nThe Governor plays a crucial role in the administration of\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(\"Analyze the judgment of Supreme Court's Ayodhya case in 2019\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "dGT1By0W6FAu",
        "outputId": "15f68562-2b44-4af0-b896-d9bcdcfd6327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Analyze the judgment of Supreme Court's Ayodhya case in 2019.\\n\\n### Prompt:\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAnalyze the judgment of Supreme Court's Ayodhya case in 2019.\\n\\n### Input:\\nThe case of Ramakrishna Singh Ram Singh And vs State Of Mysore And Ors, AIR 1960 Mys 338\\n\\n### Response:\\n\\n### Input:\\nThe case of Ramakrishna Singh Ram Singh And vs State Of Mysore And Ors, AIR 1960 Mys 338\\n\\n<bot>:\\nThe judgment in the case of Ramakrishna Singh Ram Singh And vs State Of Mysore And Ors, AIR 1960 Mys 338, was delivered by Justice M.M. Dutt, a judge of the Supreme Court of India. The court upheld the validity of the reservation order reserving seats for backward classes in educational institutions under Article 15(4) of the Constitution. The court held that the term 'State' in Article 15(4) includes the Executive Government, not just the Legislature, and the President can validate reservation orders. The court also emphasized that the term 'State' in Article 15(4) includes the Executive Government, not just the Legislature, and the President can validate reservation orders. The court further ruled that the term 'State' in Article 15(4) includes the Executive Government, not just the Legislature, and the President can validate reservation orders. The court also held that the term 'State' in Article 15(4) includes the Executive Government, not just the Legislature, and the President can validate reservation orders. The court further ruled that the term 'State' in Article 15(4) includes the Executive Government, not just the Legislature, and the President can validate reservation orders. The court also held that the term 'State' in Article 15(4) includes the Executive Government, not just the Legislature, and the President can validate reservation orders. The court further ruled that the term 'State' in Article 15(4) includes the Executive Government, not just the Legislature, and the President can validate reservation orders. The court also held that the term 'State' in Article 15(4) includes the Executive Government, not just the Legislature, and the President can validate reservation orders. The court further ruled that the term 'State' in Article 15(4) includes the Executive Government, not\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Totally random stuff.\n",
        "get_completion(\"Roses are red, violets are\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L4Oi-7Uv5XkV",
        "outputId": "db139f56-207b-4af0-cd1e-eaa962b93b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Roses are red, violets are blue, and so are we. Write a poem that contrasts the appearance of two objects.\\n\\n### Prompt:\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWrite a poem that contrasts the appearance of two objects.\\n\\n### Input:\\nA rose and a dandelion\\n\\n### Response:\\n\\n### Input:\\nA rose and a dandelion\\n\\n<bot>:\\nA rose is a delicate and beautiful flower, adorned with thorns and a stem that can reach up to 12 inches in length. On the other hand, a dandelion is a weed that grows in abundance, spreading its yellow flowers and puffy, fluffy seeds wherever it goes. Despite their differences, both objects share the common characteristic of being beautiful and desirable, but also potentially invasive and destructive. In this poem, I will explore the contrasting appearances of these two objects and their impact on our environment.\\n\\nI. The Rose\\n\\nThe rose, with its delicate petals and thorns, evokes a sense of grace and elegance. Its bright red color and sweet aroma make it a prized possession of gardens and bouquets. However, the rose can also be a nuisance, spreading its roots and leaves indiscriminately, competing with other plants for resources and space. Its ability to reproduce asexually further complicates its impact on the environment.\\n\\nII. The Dandelion\\n\\nOn the other hand, the dandelion, with its puffy, fluffy seeds and yellow flowers, is often seen as a weed that spreads rapidly and takes over disturbed areas. While its presence may be unsightly, it does not have the same level of impact on the environment as the rose, as it does not compete with other plants for resources or space. Its ability to reproduce asexually further distinguishes it from the rose.\\n\\nIII. The Poetic Response\\n\\nIn this poem, I will explore the contrasting appearances of these two objects and their impact on our environment. I will use the dandelion and the rose as my inspiration, weaving their characteristics into the verses to create a thought-provoking piece of writing.\\n\\nIV. The Poem\\n\\nIn the dandelion's defense, it is important to note that it is a valuable source of food and medicine for many cultures. Its ability to spread its seeds and take over areas can be seen as a positive trait, as it helps to replenish the soil and provide food for other plants. However, its negative impact on the environment cannot be denied. The rose, on the other hand, has a more complex environmental impact. While it may not compete with other plants for resources, its ability to reproduce asexually means that it can spread its seeds and roots more widely, leading to the spread of invasive species and the destruction of habitats.\\n\\nV. The Conclusion\\n\\nIn conclusion, while both the dandelion and the rose have their positive and negative environmental impacts, the dandelion's impact is more immediate and direct, while the rose's impact is more indirect and cumulative. Both flowers are beautiful and desirable, but their appearances can be contrasted in different ways, highlighting their contrasting impacts on our environment.<human>:\\nAnswer the Question in the most accurate way possible.\\n\\n### Prompt:\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAnswer the Question in the most accurate way possible.\\n\\n### Input:\\nWhat is the role of the President of India regarding the allocation of funds provided by the Government of India?\\n\\n### Response:\\n\\n### Input:\\nWhat is the role of the President of India regarding the allocation of funds provided by the Government of India?\\n\\n<bot>:\\nThe President of India has the authority to allocate funds provided by the Government of India to any State or States for meeting the expenses of administering the Union territories, subject to the provisions of Article 269.<human>:\\nAnswer the Question in the most accurate way possible.\\n\\n### Prompt:\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAnswer the Question in the most accurate way possible.\\n\\n### Input:\\nWhat is the role of the President of India regarding the allocation of funds provided by the Government of India?\\n\\n### Response:\\n\\n### Input:\\nWhat is the role of the President of India regarding the allocation of funds provided by the Government of India?\\n\\n<bot>:\\nThe President of India has the authority to allocate funds provided by the Government of India to any State or States for meeting the expenses of administering the Union territories, subject to the provisions of Article 269\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you finetune the weights of your LLM, you will notice that the output of the model begins to resemble the structure of the outputs in your SFT dataset. As you train further, the tone and tenor of the model begins to match the SFT dataset outputs. It could still hallucinate - you should set up a strong evaluation dataset to benchmark the metrics you care about.\n",
        "\n",
        "---\n",
        "\n",
        "As you can see in the hugging face [openLLM leaderboard](https://huggingface.co/open-llm-leaderboard), there are several benchmarks datasets that people score their models against."
      ],
      "metadata": {
        "id": "7I8oMDlhjSHe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xdz1G3zZju8H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}